"""
å¤©æ°”æ•°æ®åˆ†æå¹³å° - Weather Data Analytics
========================================

ç¯å¢ƒè¦æ±‚:
- Python 3.8+
- streamlit >= 1.28.0
- pandas >= 1.5.0
- numpy >= 1.20.0
- openpyxl >= 3.0.0

è¯´æ˜: å…¶ä»–ä¾èµ–åŒ…å°†è‡ªåŠ¨å®‰è£…
"""

import streamlit as st
import pandas as pd
import datetime
import re
import io
import numpy as np
import warnings
import subprocess
import sys
from typing import Dict, List, Optional, Tuple

# è‡ªåŠ¨å®‰è£…ä¾èµ–åŒ…å‡½æ•°
@st.cache_resource
def install_and_import_packages():
    """è‡ªåŠ¨å®‰è£…å¹¶å¯¼å…¥æ‰€éœ€çš„åŒ…"""
    packages_to_install = []
    
    try:
        import matplotlib.pyplot as plt
        import matplotlib.dates as mdates
    except ImportError:
        packages_to_install.append('matplotlib')
    
    try:
        import seaborn as sns
    except ImportError:
        packages_to_install.append('seaborn')
    
    # å¦‚æœéœ€è¦å®‰è£…åŒ…
    if packages_to_install:
        with st.spinner(f"æ­£åœ¨è‡ªåŠ¨å®‰è£…ä¾èµ–åŒ…: {', '.join(packages_to_install)}..."):
            for package in packages_to_install:
                try:
                    subprocess.check_call([sys.executable, "-m", "pip", "install", package], 
                                        stdout=subprocess.DEVNULL, 
                                        stderr=subprocess.DEVNULL)
                except Exception as e:
                    st.warning(f"è‡ªåŠ¨å®‰è£… {package} å¤±è´¥ï¼Œå°†ä½¿ç”¨æ›¿ä»£æ–¹æ¡ˆ")
    
    # é‡æ–°å¯¼å…¥
    try:
        import matplotlib.pyplot as plt
        import matplotlib.dates as mdates
        import seaborn as sns
        return plt, mdates, sns, True
    except ImportError:
        return None, None, None, False

# å°è¯•è‡ªåŠ¨å®‰è£…å’Œå¯¼å…¥
plt, mdates, sns, has_matplotlib = install_and_import_packages()

# å¿½ç•¥è­¦å‘Š
warnings.filterwarnings('ignore')

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="Weather Data Analytics",
    page_icon="ğŸŒ¤ï¸",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# å¤©æ°”ä¸»é¢˜CSSæ ·å¼
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');
    
    .main {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 25%, #f093fb 50%, #f5576c 75%, #4facfe 100%);
        background-size: 400% 400%;
        animation: gradientShift 15s ease infinite;
        min-height: 100vh;
    }
    
    @keyframes gradientShift {
        0% { background-position: 0% 50%; }
        50% { background-position: 100% 50%; }
        100% { background-position: 0% 50%; }
    }
    
    .weather-header {
        background: rgba(255, 255, 255, 0.15);
        backdrop-filter: blur(20px);
        border: 1px solid rgba(255, 255, 255, 0.2);
        border-radius: 24px;
        padding: 3rem 2rem;
        margin: 2rem 0;
        text-align: center;
        color: white;
        box-shadow: 0 8px 32px rgba(0, 0, 0, 0.1);
        position: relative;
        overflow: hidden;
    }
    
    .weather-header::before {
        content: '';
        position: absolute;
        top: -50%;
        left: -50%;
        width: 200%;
        height: 200%;
        background: radial-gradient(circle, rgba(255,255,255,0.1) 0%, transparent 70%);
        animation: float 6s ease-in-out infinite;
    }
    
    @keyframes float {
        0%, 100% { transform: translateY(0px) rotate(0deg); }
        50% { transform: translateY(-20px) rotate(180deg); }
    }
    
    .weather-card {
        background: rgba(255, 255, 255, 0.95);
        backdrop-filter: blur(10px);
        border: 1px solid rgba(255, 255, 255, 0.3);
        border-radius: 20px;
        padding: 2rem;
        margin: 1rem 0;
        box-shadow: 0 8px 32px rgba(0, 0, 0, 0.1);
        transition: all 0.3s ease;
        position: relative;
        overflow: hidden;
    }
    
    .weather-card:hover {
        transform: translateY(-5px);
        box-shadow: 0 16px 48px rgba(0, 0, 0, 0.15);
    }
    
    .weather-card::before {
        content: '';
        position: absolute;
        top: 0;
        left: 0;
        right: 0;
        height: 4px;
        background: linear-gradient(90deg, #667eea, #764ba2);
        border-radius: 20px 20px 0 0;
    }
    
    .metric-weather {
        background: linear-gradient(135deg, rgba(102, 126, 234, 0.1) 0%, rgba(118, 75, 162, 0.1) 100%);
        border: 1px solid rgba(102, 126, 234, 0.2);
        border-radius: 16px;
        padding: 1.5rem;
        text-align: center;
        margin: 0.5rem 0;
        transition: all 0.3s ease;
        position: relative;
        overflow: hidden;
    }
    
    .metric-weather:hover {
        transform: scale(1.02);
        background: linear-gradient(135deg, rgba(102, 126, 234, 0.15) 0%, rgba(118, 75, 162, 0.15) 100%);
    }
    
    .metric-weather h3 {
        font-family: 'Inter', sans-serif;
        font-weight: 700;
        font-size: 2.2rem;
        margin: 0;
        background: linear-gradient(90deg, #667eea, #764ba2);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        background-clip: text;
    }
    
    .metric-weather p {
        font-family: 'Inter', sans-serif;
        font-weight: 500;
        color: #666;
        margin: 0.5rem 0 0 0;
        font-size: 0.9rem;
        text-transform: uppercase;
        letter-spacing: 1px;
    }
    
    .upload-zone {
        background: rgba(255, 255, 255, 0.9);
        border: 2px dashed rgba(102, 126, 234, 0.4);
        border-radius: 20px;
        padding: 2rem;
        text-align: center;
        transition: all 0.3s ease;
        position: relative;
        overflow: hidden;
    }
    
    .upload-zone:hover {
        border-color: rgba(102, 126, 234, 0.8);
        background: rgba(255, 255, 255, 0.95);
        transform: translateY(-2px);
    }
    
    .success-weather {
        background: linear-gradient(135deg, rgba(86, 171, 47, 0.1) 0%, rgba(168, 230, 207, 0.1) 100%);
        border: 1px solid rgba(86, 171, 47, 0.3);
        border-radius: 16px;
        padding: 1.5rem;
        margin: 1rem 0;
        color: #2d5016;
        backdrop-filter: blur(10px);
    }
    
    .weather-tabs .stTabs [data-baseweb="tab-list"] {
        gap: 4px;
        background: rgba(255, 255, 255, 0.1);
        padding: 6px;
        border-radius: 16px;
        backdrop-filter: blur(10px);
    }
    
    .weather-tabs .stTabs [data-baseweb="tab"] {
        height: 50px;
        background: rgba(255, 255, 255, 0.2);
        border-radius: 12px;
        color: white;
        font-weight: 600;
        border: none;
        transition: all 0.3s ease;
    }
    
    .weather-tabs .stTabs [aria-selected="true"] {
        background: rgba(255, 255, 255, 0.9);
        color: #667eea;
        box-shadow: 0 4px 16px rgba(0, 0, 0, 0.1);
    }
    
    .stButton > button {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: none;
        border-radius: 16px;
        padding: 0.75rem 2rem;
        font-weight: 600;
        font-family: 'Inter', sans-serif;
        transition: all 0.3s ease;
        box-shadow: 0 4px 16px rgba(102, 126, 234, 0.3);
    }
    
    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 8px 24px rgba(102, 126, 234, 0.4);
        background: linear-gradient(135deg, #5a67d8 0%, #6b46c1 100%);
    }
    
    .weather-icon {
        font-size: 3rem;
        margin-bottom: 1rem;
        display: block;
        animation: bounce 2s infinite;
    }
    
    @keyframes bounce {
        0%, 20%, 53%, 80%, 100% { transform: translate3d(0,0,0); }
        40%, 43% { transform: translate3d(0,-8px,0); }
        70% { transform: translate3d(0,-4px,0); }
        90% { transform: translate3d(0,-2px,0); }
    }
    
    .weather-subtitle {
        font-family: 'Inter', sans-serif;
        font-weight: 300;
        font-size: 1.2rem;
        opacity: 0.9;
        margin-top: 0.5rem;
    }
    
    .weather-title {
        font-family: 'Inter', sans-serif;
        font-weight: 700;
        font-size: 3.5rem;
        margin: 0;
        text-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
    }
    
    .download-btn {
        background: linear-gradient(135deg, #56ab2f 0%, #a8e6cf 100%);
        color: white;
        border: none;
        border-radius: 12px;
        padding: 0.6rem 1.5rem;
        font-weight: 600;
        margin: 0.3rem;
        transition: all 0.3s ease;
        box-shadow: 0 4px 12px rgba(86, 171, 47, 0.3);
    }
    
    .floating-particles {
        position: fixed;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
        pointer-events: none;
        z-index: -1;
    }
    
    .particle {
        position: absolute;
        background: rgba(255, 255, 255, 0.1);
        border-radius: 50%;
        animation: floatUp 15s infinite linear;
    }
    
    @keyframes floatUp {
        0% {
            opacity: 0;
            transform: translateY(100vh) scale(0);
        }
        10% {
            opacity: 1;
        }
        90% {
            opacity: 1;
        }
        100% {
            opacity: 0;
            transform: translateY(-100vh) scale(1);
        }
    }
    
    .data-preview {
        background: rgba(255, 255, 255, 0.95);
        border-radius: 16px;
        padding: 1rem;
        margin: 1rem 0;
        backdrop-filter: blur(10px);
        box-shadow: 0 4px 16px rgba(0, 0, 0, 0.1);
    }
</style>

<!-- æµ®åŠ¨ç²’å­æ•ˆæœ -->
<div class="floating-particles">
    <div class="particle" style="left: 10%; width: 4px; height: 4px; animation-delay: 0s;"></div>
    <div class="particle" style="left: 20%; width: 6px; height: 6px; animation-delay: 2s;"></div>
    <div class="particle" style="left: 30%; width: 3px; height: 3px; animation-delay: 4s;"></div>
    <div class="particle" style="left: 40%; width: 5px; height: 5px; animation-delay: 6s;"></div>
    <div class="particle" style="left: 50%; width: 4px; height: 4px; animation-delay: 8s;"></div>
    <div class="particle" style="left: 60%; width: 6px; height: 6px; animation-delay: 10s;"></div>
    <div class="particle" style="left: 70%; width: 3px; height: 3px; animation-delay: 12s;"></div>
    <div class="particle" style="left: 80%; width: 5px; height: 5px; animation-delay: 14s;"></div>
    <div class="particle" style="left: 90%; width: 4px; height: 4px; animation-delay: 16s;"></div>
</div>
""", unsafe_allow_html=True)

def convert_date_to_sortable(date_str: str) -> str:
    """å°†æ—¥æœŸå­—ç¬¦ä¸²è½¬æ¢ä¸ºå¯æ’åºçš„æ ¼å¼"""
    try:
        parts = date_str.split('/')
        if len(parts) == 3:
            year, month, day = parts
            month = month.zfill(2)
            day = day.zfill(2)
            return f"{year}{month}{day}"
    except:
        pass
    return date_str

def force_standardize_date(date_str):
    """å¼ºåˆ¶æ ‡å‡†åŒ–æ—¥æœŸæ ¼å¼ï¼Œç¡®ä¿æœˆä»½å’Œæ—¥æœŸéƒ½æ˜¯ä¸¤ä½æ•°"""
    if pd.isna(date_str) or str(date_str).strip() == '':
        return date_str

    date_str = str(date_str).strip()

    # å¤„ç†ä¸åŒåˆ†éš”ç¬¦ï¼Œç»Ÿä¸€è½¬æ¢ä¸º/
    if '-' in date_str:
        date_str = date_str.replace('-', '/')

    # å¦‚æœåŒ…å«/ï¼Œåˆ™å¤„ç†
    if '/' in date_str:
        parts = date_str.split('/')
        if len(parts) == 3:
            try:
                year = int(parts[0])
                month = int(parts[1])
                day = int(parts[2])
                # å¼ºåˆ¶æ ¼å¼åŒ–ä¸ºä¸¤ä½æ•°
                result = f"{year:04d}/{month:02d}/{day:02d}"
                return result
            except:
                pass

    return date_str

def create_weather_visualization(df, title, chart_type="line"):
    """åˆ›å»ºå¤©æ°”ä¸»é¢˜çš„æ•°æ®å¯è§†åŒ–å›¾è¡¨"""
    try:
        if df.empty:
            return None
            
        # è·å–æ—¥æœŸåˆ—ï¼ˆé€šå¸¸æ˜¯ç¬¬ä¸€åˆ—ï¼‰
        date_col = df.columns[0]
        
        # å°è¯•è½¬æ¢æ—¥æœŸæ ¼å¼
        try:
            df_viz = df.copy()
            df_viz[date_col] = pd.to_datetime(df_viz[date_col], errors='coerce')
            df_viz = df_viz.dropna(subset=[date_col])
            df_viz = df_viz.sort_values(date_col)
        except:
            df_viz = df.copy()
        
        # å¦‚æœmatplotlibå¯ç”¨ï¼Œä½¿ç”¨matplotlib
        if has_matplotlib and plt is not None:
            return create_matplotlib_chart(df_viz, title, chart_type, date_col)
        else:
            # ä½¿ç”¨Streamlitå†…ç½®å›¾è¡¨ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ
            return create_streamlit_chart(df_viz, title, chart_type, date_col)
            
    except Exception as e:
        st.warning(f"å›¾è¡¨åˆ›å»ºå¤±è´¥: {str(e)}")
        return None

def create_matplotlib_chart(df_viz, title, chart_type, date_col):
    """ä½¿ç”¨matplotlibåˆ›å»ºå›¾è¡¨"""
    # å¤©æ°”ä¸»é¢˜é…è‰²
    colors = ['#667eea', '#764ba2', '#f093fb', '#f5576c', '#4facfe', '#00f2fe', '#43e97b']
    
    if chart_type == "line":
        # å¯»æ‰¾æ•°å€¼åˆ—
        numeric_cols = df_viz.select_dtypes(include=[np.number]).columns.tolist()
        
        if len(numeric_cols) > 0:
            fig, ax = plt.subplots(figsize=(12, 6))
            fig.patch.set_facecolor('white')
            fig.patch.set_alpha(0.9)
            
            # æ·»åŠ å¤šä¸ªæ•°å€¼åˆ—çš„çº¿å›¾
            for i, col in enumerate(numeric_cols[:5]):
                valid_data = df_viz[[date_col, col]].dropna()
                if not valid_data.empty:
                    ax.plot(valid_data[date_col], valid_data[col], 
                           color=colors[i % len(colors)], 
                           linewidth=3, 
                           marker='o', 
                           markersize=6,
                           label=col,
                           alpha=0.8)
            
            ax.set_title(title, fontsize=16, fontweight='bold', color='#333', pad=20)
            ax.set_xlabel('æ—¥æœŸ', fontsize=12, color='#666')
            ax.set_ylabel('æ•°å€¼', fontsize=12, color='#666')
            
            # ç¾åŒ–æ ·å¼
            ax.grid(True, alpha=0.3)
            ax.spines['top'].set_visible(False)
            ax.spines['right'].set_visible(False)
            ax.spines['left'].set_color('#ddd')
            ax.spines['bottom'].set_color('#ddd')
            
            if len(numeric_cols) > 1:
                ax.legend(loc='upper left', frameon=False)
            
            # æ ¼å¼åŒ–xè½´æ—¥æœŸ
            if df_viz[date_col].dtype == 'datetime64[ns]' and mdates is not None:
                ax.xaxis.set_major_formatter(mdates.DateFormatter('%m/%d'))
                plt.setp(ax.xaxis.get_majorticklabels(), rotation=45)
            
            plt.tight_layout()
            return fig
            
    elif chart_type == "bar":
        # åˆ›å»ºæŸ±çŠ¶å›¾
        if 'ä¸‰ç«¯' in df_viz.columns:
            # æŒ‰æ¸ é“åˆ†ç»„ç»Ÿè®¡
            numeric_cols = df_viz.select_dtypes(include=[np.number]).columns.tolist()
            if numeric_cols:
                agg_data = df_viz.groupby('ä¸‰ç«¯')[numeric_cols[0]].sum().reset_index()
                
                fig, ax = plt.subplots(figsize=(10, 6))
                fig.patch.set_facecolor('white')
                fig.patch.set_alpha(0.9)
                
                bars = ax.bar(agg_data['ä¸‰ç«¯'], agg_data[numeric_cols[0]], 
                             color=colors[:len(agg_data)], 
                             alpha=0.8,
                             edgecolor='white',
                             linewidth=2)
                
                ax.set_title(title, fontsize=16, fontweight='bold', color='#333', pad=20)
                ax.set_xlabel('æ¸ é“', fontsize=12, color='#666')
                ax.set_ylabel(numeric_cols[0], fontsize=12, color='#666')
                
                # ç¾åŒ–æ ·å¼
                ax.grid(True, alpha=0.3, axis='y')
                ax.spines['top'].set_visible(False)
                ax.spines['right'].set_visible(False)
                ax.spines['left'].set_color('#ddd')
                ax.spines['bottom'].set_color('#ddd')
                
                # åœ¨æŸ±å­ä¸Šæ˜¾ç¤ºæ•°å€¼
                for bar in bars:
                    height = bar.get_height()
                    ax.text(bar.get_x() + bar.get_width()/2., height,
                           f'{height:,.0f}',
                           ha='center', va='bottom', fontweight='bold')
                
                plt.tight_layout()
                return fig
    
    return None

def create_streamlit_chart(df_viz, title, chart_type, date_col):
    """ä½¿ç”¨Streamlitå†…ç½®å›¾è¡¨ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ"""
    st.subheader(title)
    
    if chart_type == "line":
        # å¯»æ‰¾æ•°å€¼åˆ—
        numeric_cols = df_viz.select_dtypes(include=[np.number]).columns.tolist()
        if len(numeric_cols) > 0:
            # å‡†å¤‡æ•°æ®ç”¨äºst.line_chart
            chart_data = df_viz.set_index(date_col)[numeric_cols[:5]]
            st.line_chart(chart_data, height=400)
            return "streamlit_chart"
            
    elif chart_type == "bar":
        if 'ä¸‰ç«¯' in df_viz.columns:
            numeric_cols = df_viz.select_dtypes(include=[np.number]).columns.tolist()
            if numeric_cols:
                agg_data = df_viz.groupby('ä¸‰ç«¯')[numeric_cols[0]].sum().reset_index()
                agg_data = agg_data.set_index('ä¸‰ç«¯')
                st.bar_chart(agg_data, height=400)
                return "streamlit_chart"
    
    return None

def process_dau_files(uploaded_files) -> Optional[Dict[str, pd.DataFrame]]:
    """å¤„ç†DAUæ–‡ä»¶ä¸Šä¼ """
    if not uploaded_files:
        return None
        
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    channel_dfs = {'mvp': [], 'and': [], 'ios': []}
    standard_columns = {'mvp': None, 'and': None, 'ios': None}
    
    processed_files = 0
    total_files = len(uploaded_files)
    
    for i, uploaded_file in enumerate(uploaded_files):
        try:
            progress = (i + 1) / total_files
            progress_bar.progress(progress)
            status_text.text(f"ğŸŒ¤ï¸ æ­£åœ¨å¤„ç†: {uploaded_file.name} ({i+1}/{total_files})")
            
            filename = uploaded_file.name
            
            if "dau" not in filename.lower():
                continue
            
            # ä»æ–‡ä»¶åä¸­æå–æ¸ é“ä¿¡æ¯
            if len(filename) > 7 and filename.startswith("dau_"):
                channel = filename[4:7]  # è·å–æ¸ é“å (mvp, and, ios)
                if channel not in channel_dfs:
                    continue
            else:
                continue
            
            # è¯»å–CSVæ–‡ä»¶
            try:
                content = uploaded_file.getvalue()
                try:
                    df = pd.read_csv(io.StringIO(content.decode('utf-8')), 
                                   na_values=[''], keep_default_na=False)
                except UnicodeDecodeError:
                    df = pd.read_csv(io.StringIO(content.decode('latin1')), 
                                   na_values=[''], keep_default_na=False)
                
            except Exception as e:
                continue
            
            if df.empty:
                continue
            
            # åˆ é™¤æŒ‡å®šçš„ä¸‰åˆ—
            columns_to_drop = ['Total Conversions', 'Re-attribution', 'Re-engagement']
            df = df.drop(columns=[col for col in columns_to_drop if col in df.columns], errors='ignore')
            
            # ä»æ–‡ä»¶åæå–æ—¥æœŸ
            try:
                date_part = filename.split('_')[-1].replace('.csv', '')
                match = re.search(r'(\d+)\.(\d+)', date_part)
                if match:
                    month, day = match.groups()
                    formatted_date = f"2025/{month}/{day}"
                else:
                    formatted_date = date_part
            except:
                formatted_date = "2025/1/1"
            
            # æ·»åŠ æ—¥æœŸåˆ—
            df.insert(0, 'date', formatted_date)
            
            # iOSç‰¹æ®Šå¤„ç†
            if channel == 'ios' and 'Average eCPIUS$2.50' in df.columns:
                df = df.drop(columns=['Average eCPIUS$2.50'])
            
            # åˆ—æ ‡å‡†åŒ–
            if standard_columns[channel] is None:
                standard_columns[channel] = df.columns.tolist()
            else:
                current_cols = df.columns.tolist()
                if current_cols != standard_columns[channel]:
                    missing_cols = [col for col in standard_columns[channel] if col not in current_cols]
                    extra_cols = [col for col in current_cols if col not in standard_columns[channel]]
                    
                    if missing_cols:
                        for col in missing_cols:
                            df[col] = 'N/A'
                    
                    if extra_cols:
                        df = df.drop(columns=extra_cols)
                    
                    df = df[standard_columns[channel]]
            
            df = df.fillna('N/A')
            channel_dfs[channel].append(df)
            processed_files += 1
            
        except Exception as e:
            continue
    
    progress_bar.progress(1.0)
    status_text.text(f"â˜€ï¸ DAUæ–‡ä»¶å¤„ç†å®Œæˆ! æˆåŠŸå¤„ç†äº† {processed_files} ä¸ªæ–‡ä»¶")
    
    if processed_files == 0:
        return None
    
    # åˆå¹¶æ•°æ®
    merged_by_channel = {}
    
    for channel, df_list in channel_dfs.items():
        if df_list:
            # ç¡®ä¿åˆ—ä¸€è‡´æ€§
            if len(df_list) > 1:
                standard_cols = list(df_list[0].columns)
                for i, df in enumerate(df_list):
                    if set(df.columns) != set(standard_cols):
                        missing = [col for col in standard_cols if col not in df.columns]
                        extra = [col for col in df.columns if col not in standard_cols]
                        
                        for col in missing:
                            df[col] = 'N/A'
                        if extra:
                            df = df.drop(columns=extra)
                        df = df[standard_cols]
                        df_list[i] = df
            
            merged_df = pd.concat(df_list, ignore_index=True)
            
            # æŒ‰æ—¥æœŸæ’åº
            try:
                merged_df['sort_key'] = merged_df['date'].apply(convert_date_to_sortable)
                merged_df = merged_df.sort_values(by='sort_key')
                merged_df = merged_df.drop(columns=['sort_key'])
            except Exception as e:
                pass
            
            merged_df = merged_df.fillna('N/A')
            
            # iOSç‰¹æ®Šå¤„ç†
            if channel == 'ios':
                expected_columns = ['date', 'Country', 'Impressions', 'Clicks', 'Installs', 'Conversion Rate',
                                  'Activity Sessions', 'Cost', 'Activity Revenue', 'Average eCPIUS$2.31',
                                  'Average DAU', 'Average MAU', 'Average DAU/MAU Rate', 'ARPDAU']
                
                extra_columns = [col for col in merged_df.columns if col not in expected_columns]
                if extra_columns:
                    merged_df = merged_df.drop(columns=extra_columns)
                
                missing_columns = [col for col in expected_columns if col not in merged_df.columns]
                if missing_columns:
                    for col in missing_columns:
                        merged_df[col] = 'N/A'
                
                merged_df = merged_df[expected_columns]
            
            merged_by_channel[channel] = merged_df
    
    return merged_by_channel

def process_retention_files(uploaded_files) -> Optional[Dict[str, pd.DataFrame]]:
    """å¤„ç†ç•™å­˜æ–‡ä»¶ä¸Šä¼ """
    if not uploaded_files:
        return None
        
    # æ¸ é“é…ç½®
    channels_config = {
        'ios': {
            'pattern': 'retention_ios.csv',
            'empty_columns': 4,
            'days': list(range(1, 8)) + [14, 30]
        },
        'ios_formal': {
            'pattern': 'retention_ios_formal.csv',
            'empty_columns': 4,
            'days': list(range(1, 8)) + [14, 30]
        },
        'mvp': {
            'pattern': 'retention_mvp.csv',
            'empty_columns': 1,
            'days': list(range(1, 8)) + [14]
        },
        'and': {
            'pattern': 'retention_and.csv',
            'empty_columns': 0,
            'days': list(range(1, 8)) + [14, 30]
        }
    }
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    processed_data = {}
    total_files = len(uploaded_files)
    
    for i, uploaded_file in enumerate(uploaded_files):
        try:
            progress = (i + 1) / total_files
            progress_bar.progress(progress)
            status_text.text(f"ğŸŒ§ï¸ æ­£åœ¨å¤„ç†: {uploaded_file.name} ({i+1}/{total_files})")
            
            filename = uploaded_file.name.lower()
            
            # åŒ¹é…æ¸ é“
            channel = None
            for ch, config in channels_config.items():
                if config['pattern'].lower() in filename:
                    channel = ch
                    break
            
            if not channel:
                continue
            
            # è¯»å–æ–‡ä»¶
            try:
                content = uploaded_file.getvalue()
                encodings = ['utf-8', 'gbk', 'gb2312', 'latin1']
                df = None
                
                for encoding in encodings:
                    try:
                        df = pd.read_csv(io.StringIO(content.decode(encoding)))
                        break
                    except UnicodeDecodeError:
                        continue
                
                if df is None:
                    continue
                
            except Exception as e:
                continue
            
            # å¤„ç†æ—¥æœŸåˆ—
            date_column = "Cohort Day"
            if date_column not in df.columns:
                possible_date_columns = ['Date', 'date', 'æ—¥æœŸ', 'DAY', 'Day', 'day']
                for col in possible_date_columns:
                    if col in df.columns:
                        date_column = col
                        break
                
                if date_column not in df.columns:
                    continue
            
            # æ’åºæ•°æ®
            try:
                df[date_column] = pd.to_datetime(df[date_column])
                df = df.sort_values(by=date_column)
            except:
                try:
                    df = df.sort_values(by=date_column)
                except:
                    pass
            
            # æ£€æŸ¥ç”¨æˆ·åˆ—
            users_column = 'Users'
            if users_column not in df.columns:
                possible_users_columns = ['users', 'ç”¨æˆ·æ•°', 'DAU', 'User Count', 'user_count']
                for col in possible_users_columns:
                    if col in df.columns:
                        users_column = col
                        break
                
                if users_column not in df.columns:
                    continue
            
            # æ·»åŠ ç©ºåˆ—
            config = channels_config[channel]
            for j in range(config['empty_columns']):
                df[' ' * (j + 1)] = None
            
            # è®¡ç®—ç•™å­˜ç‡
            for day in config['days']:
                retention_column = f'sessions - Unique users - day {day} - partial'
                alternative_column = f'sessions - Unique users - day {day}'
                
                if retention_column in df.columns:
                    df[f'day{day}'] = (df[retention_column] / df[users_column]).round(4)
                elif alternative_column in df.columns:
                    df[retention_column] = df[alternative_column]
                    df[f'day{day}'] = (df[retention_column] / df[users_column]).round(4)
            
            processed_data[channel] = df
            
        except Exception as e:
            continue
    
    progress_bar.progress(1.0)
    status_text.text(f"â›… ç•™å­˜æ–‡ä»¶å¤„ç†å®Œæˆ! æˆåŠŸå¤„ç†äº† {len(processed_data)} ä¸ªæ–‡ä»¶")
    
    return processed_data if processed_data else None

def create_integrated_dau(merged_data: Dict[str, pd.DataFrame]) -> pd.DataFrame:
    """æ•´åˆä¸‰ä¸ªæ¸ é“çš„DAUæ•°æ®"""
    if not merged_data:
        return pd.DataFrame()
    
    integrated_dfs = []
    
    for channel, df in merged_data.items():
        df_copy = df.copy()
        # æ˜ å°„æ¸ é“å
        channel_mapping = {'and': 'android', 'mvp': 'mvp', 'ios': 'ios'}
        df_copy.insert(1, 'ä¸‰ç«¯', channel_mapping.get(channel, channel))
        integrated_dfs.append(df_copy)
    
    if not integrated_dfs:
        return pd.DataFrame()
    
    try:
        # ç»Ÿä¸€åˆ—
        all_columns = []
        for df in integrated_dfs:
            all_columns.extend(df.columns.tolist())
        
        unique_columns = list(dict.fromkeys(all_columns))
        
        standardized_dfs = []
        for df in integrated_dfs:
            df_copy = df.copy()
            
            for col in unique_columns:
                if col not in df_copy.columns:
                    df_copy[col] = 'N/A'
            
            df_copy = df_copy[unique_columns]
            standardized_dfs.append(df_copy)
        
        integrated_df = pd.concat(standardized_dfs, ignore_index=True)
        
        # ç»Ÿä¸€æ—¥æœŸæ ¼å¼
        if 'date' in integrated_df.columns:
            integrated_df['date'] = integrated_df['date'].apply(force_standardize_date)
        
        # æ’åº
        try:
            integrated_df['sort_key'] = integrated_df['date'].apply(convert_date_to_sortable)
            channel_order = {"mvp": 0, "android": 1, "ios": 2}
            integrated_df["æ¸ é“æ’åº"] = integrated_df["ä¸‰ç«¯"].map(channel_order)
            integrated_df = integrated_df.sort_values(by=['sort_key', 'æ¸ é“æ’åº'])
            integrated_df = integrated_df.drop(columns=['sort_key', 'æ¸ é“æ’åº'])
        except Exception as e:
            pass
        
        integrated_df = integrated_df.fillna('N/A')
        
        # åªä¿ç•™å‰15åˆ—åŠ ä¸‰ç«¯åˆ—
        if len(integrated_df.columns) > 16:
            first_15_cols = integrated_df.iloc[:, :15].columns.tolist()
            if "ä¸‰ç«¯" in integrated_df.columns and "ä¸‰ç«¯" not in first_15_cols:
                cols_to_keep = first_15_cols + ["ä¸‰ç«¯"]
                integrated_df = integrated_df[cols_to_keep]
        
        return integrated_df
        
    except Exception as e:
        return pd.DataFrame()

def create_integrated_retention(retention_data: Dict[str, pd.DataFrame]) -> pd.DataFrame:
    """æ•´åˆç•™å­˜æ•°æ®"""
    if not retention_data:
        return pd.DataFrame()
    
    integrated_dfs = []
    
    # æ¸ é“æ˜ å°„
    channel_mapping = {'and': 'android', 'mvp': 'mvp', 'ios': 'ios', 'ios_formal': 'ios'}
    
    # æœŸæœ›çš„åˆ—é¡ºåº
    expected_columns = [
        "Cohort Day", "Ltv Country", "Campaign Id", "Keywords", "Users", "Cost", "Average eCPI",
        "sessions - Unique users - day 1 - partial", "sessions - Unique users - day 2 - partial",
        "sessions - Unique users - day 3 - partial", "sessions - Unique users - day 4 - partial",
        "sessions - Unique users - day 5 - partial", "sessions - Unique users - day 6 - partial",
        "sessions - Unique users - day 7 - partial", "sessions - Unique users - day 14 - partial",
        "sessions - Unique users - day 30 - partial", "Unnamed: 16", "Unnamed: 17", "Unnamed: 18",
        "day1", "day2", "day3", "day4", "day5", "day6", "day7", "day14", "day30",
        "ä¸‰ç«¯"
    ]
    
    for channel, df in retention_data.items():
        df_copy = df.copy()
        
        # æ˜ å°„æ¸ é“å
        mapped_channel = channel_mapping.get(channel, channel)
        df_copy["ä¸‰ç«¯"] = mapped_channel
        
        # åˆ—åä¿®æ­£
        if channel in ["mvp", "and"]:
            alt_day14 = "sessions - Unique users - day 14- partial"
            std_day14 = "sessions - Unique users - day 14 - partial"
            if alt_day14 in df_copy.columns and std_day14 not in df_copy.columns:
                df_copy = df_copy.rename(columns={alt_day14: std_day14})
            
            alt_day30 = "sessions - Unique users - day 30- partial"
            std_day30 = "sessions - Unique users - day 30 - partial"
            if alt_day30 in df_copy.columns and std_day30 not in df_copy.columns:
                df_copy = df_copy.rename(columns={alt_day30: std_day30})
        
        integrated_dfs.append(df_copy)
    
    if not integrated_dfs:
        return pd.DataFrame()
    
    try:
        # åˆå¹¶æ•°æ®
        integrated_df = pd.concat(integrated_dfs, ignore_index=True)
        
        # ç»Ÿä¸€æ—¥æœŸæ ¼å¼
        if "Cohort Day" in integrated_df.columns:
            integrated_df["Cohort Day"] = integrated_df["Cohort Day"].apply(force_standardize_date)
        
        # é‡æ–°æ’åºåˆ—å¹¶å¡«å……ç¼ºå¤±åˆ—
        final_columns = []
        for col in expected_columns:
            if col not in integrated_df.columns:
                integrated_df[col] = None
            final_columns.append(col)
        
        existing_cols = [col for col in final_columns if col in integrated_df.columns]
        integrated_df = integrated_df[existing_cols]
        
        # æ¸…ç©ºUnnamedåˆ—
        unnamed_cols = [col for col in integrated_df.columns if 'Unnamed' in col]
        for col in unnamed_cols:
            integrated_df[col] = ''
        
        # æ’åº
        try:
            channel_order = {"mvp": 0, "android": 1, "ios": 2}
            integrated_df["æ¸ é“æ’åº"] = integrated_df["ä¸‰ç«¯"].map(channel_order)
            integrated_df = integrated_df.sort_values(by=["Cohort Day", "æ¸ é“æ’åº"])
            integrated_df = integrated_df.drop(columns=["æ¸ é“æ’åº"])
        except Exception as e:
            pass
        
        integrated_df = integrated_df.fillna('N/A')
        
        return integrated_df
        
    except Exception as e:
        return pd.DataFrame()

def main():
    # å¤©æ°”ä¸»é¢˜æ ‡é¢˜
    st.markdown("""
    <div class="weather-header">
        <div class="weather-icon">ğŸŒ¤ï¸</div>
        <h1 class="weather-title">Weather Data Analytics</h1>
        <p class="weather-subtitle">å¢¨è¿¹å¤©æ°”æ•°æ®åˆ†æå¹³å° Â· æ™ºèƒ½å¤„ç† Â· æ·±åº¦æ´å¯Ÿ</p>
    </div>
    """, unsafe_allow_html=True)
    
    # æ ¸å¿ƒåŠŸèƒ½åŒºåŸŸ
    st.markdown("## â˜€ï¸ æ•°æ®å¤„ç†ä¸­å¿ƒ")
    
    # åˆ›å»ºä¸¤åˆ—å¸ƒå±€
    col1, col2 = st.columns(2, gap="large")
    
    with col1:
        st.markdown("""
        <div class="weather-card">
            <div class="weather-icon">ğŸ“Š</div>
            <h3>DAUæ•°æ®åˆ†æ</h3>
            <p style="color: #666; margin-bottom: 1.5rem;">
                â€¢ æ™ºèƒ½æ–‡ä»¶è¯†åˆ«ä¸è§£æ<br>
                â€¢ å¤šæ¸ é“æ•°æ®è‡ªåŠ¨åˆå¹¶<br>
                â€¢ å®æ—¶è¶‹åŠ¿åˆ†æä¸é¢„æµ‹
            </p>
        </div>
        """, unsafe_allow_html=True)
        
        # DAUæ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
        st.markdown('<div class="upload-zone">', unsafe_allow_html=True)
        dau_files = st.file_uploader(
            "ğŸŒ¤ï¸ æ‹–å…¥DAUæ•°æ®æ–‡ä»¶",
            type=['csv'],
            accept_multiple_files=True,
            help="æ”¯æŒæ ¼å¼: dau_æ¸ é“_æ—¥æœŸ.csv",
            key="dau_uploader",
            label_visibility="collapsed"
        )
        st.markdown('</div>', unsafe_allow_html=True)
        
        if dau_files:
            st.markdown(f"""
            <div class="success-weather">
                âœ¨ å·²é€‰æ‹© <strong>{len(dau_files)}</strong> ä¸ªDAUæ–‡ä»¶ï¼Œå‡†å¤‡å¼€å§‹åˆ†æ
            </div>
            """, unsafe_allow_html=True)
            
            if st.button("ğŸš€ å¼€å§‹DAUæ•°æ®åˆ†æ", type="primary", key="process_dau"):
                with st.spinner("ğŸ”„ æ­£åœ¨è¿›è¡Œæ™ºèƒ½æ•°æ®åˆ†æ..."):
                    st.session_state.dau_results = process_dau_files(dau_files)
                
                if st.session_state.dau_results:
                    st.balloons()
                    st.markdown("""
                    <div class="success-weather">
                        ğŸ‰ DAUæ•°æ®åˆ†æå®Œæˆï¼å·²ç”Ÿæˆå®Œæ•´çš„å¯è§†åŒ–æŠ¥å‘Šå’Œè¶‹åŠ¿åˆ†æ
                    </div>
                    """, unsafe_allow_html=True)
    
    with col2:
        st.markdown("""
        <div class="weather-card">
            <div class="weather-icon">ğŸ”„</div>
            <h3>ç•™å­˜æ•°æ®åˆ†æ</h3>
            <p style="color: #666; margin-bottom: 1.5rem;">
                â€¢ è‡ªåŠ¨è®¡ç®—å¤šæ—¥ç•™å­˜ç‡<br>
                â€¢ æ¸ é“ç•™å­˜è¡¨ç°å¯¹æ¯”<br>
                â€¢ ç”¨æˆ·è¡Œä¸ºæ·±åº¦åˆ†æ
            </p>
        </div>
        """, unsafe_allow_html=True)
        
        # ç•™å­˜æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
        st.markdown('<div class="upload-zone">', unsafe_allow_html=True)
        retention_files = st.file_uploader(
            "ğŸŒ§ï¸ æ‹–å…¥ç•™å­˜æ•°æ®æ–‡ä»¶",
            type=['csv'],
            accept_multiple_files=True,
            help="æ”¯æŒæ ¼å¼: retention_æ¸ é“.csv",
            key="retention_uploader",
            label_visibility="collapsed"
        )
        st.markdown('</div>', unsafe_allow_html=True)
        
        if retention_files:
            st.markdown(f"""
            <div class="success-weather">
                âœ¨ å·²é€‰æ‹© <strong>{len(retention_files)}</strong> ä¸ªç•™å­˜æ–‡ä»¶ï¼Œå‡†å¤‡å¼€å§‹åˆ†æ
            </div>
            """, unsafe_allow_html=True)
            
            if st.button("ğŸš€ å¼€å§‹ç•™å­˜æ•°æ®åˆ†æ", type="primary", key="process_retention"):
                with st.spinner("ğŸ”„ æ­£åœ¨è¿›è¡Œæ™ºèƒ½ç•™å­˜åˆ†æ..."):
                    st.session_state.retention_results = process_retention_files(retention_files)
                
                if st.session_state.retention_results:
                    st.balloons()
                    st.markdown("""
                    <div class="success-weather">
                        ğŸ‰ ç•™å­˜æ•°æ®åˆ†æå®Œæˆï¼å·²ç”Ÿæˆç•™å­˜ç‡è¶‹åŠ¿å’Œç”¨æˆ·è¡Œä¸ºæ´å¯Ÿ
                    </div>
                    """, unsafe_allow_html=True)
    
    # DAUæ•°æ®å¯è§†åŒ–å’Œç»“æœå±•ç¤º
    if 'dau_results' in st.session_state and st.session_state.dau_results:
        st.markdown("---")
        st.markdown("## ğŸ“ˆ DAUæ•°æ®æ´å¯ŸæŠ¥å‘Š")
        
        # åˆ›å»ºæ•´åˆæ•°æ®
        integrated_dau = create_integrated_dau(st.session_state.dau_results)
        
        if not integrated_dau.empty:
            # å…³é”®æŒ‡æ ‡ä»ªè¡¨æ¿
            metric_cols = st.columns(4)
            with metric_cols[0]:
                st.markdown(f"""
                <div class="metric-weather">
                    <h3>{len(st.session_state.dau_results)}</h3>
                    <p>æ•°æ®æ¸ é“</p>
                </div>
                """, unsafe_allow_html=True)
            
            with metric_cols[1]:
                total_rows = sum(len(df) for df in st.session_state.dau_results.values())
                st.markdown(f"""
                <div class="metric-weather">
                    <h3>{total_rows:,}</h3>
                    <p>æ•°æ®è®°å½•</p>
                </div>
                """, unsafe_allow_html=True)
            
            with metric_cols[2]:
                st.markdown(f"""
                <div class="metric-weather">
                    <h3>{len(integrated_dau):,}</h3>
                    <p>æ•´åˆè®°å½•</p>
                </div>
                """, unsafe_allow_html=True)
            
            with metric_cols[3]:
                if 'Installs' in integrated_dau.columns:
                    # å°è¯•è½¬æ¢å®‰è£…é‡ä¸ºæ•°å€¼
                    try:
                        install_col = integrated_dau['Installs'].replace('N/A', '0')
                        install_col = install_col.astype(str).str.replace(',', '')
                        total_installs = pd.to_numeric(install_col, errors='coerce').sum()
                        if pd.isna(total_installs):
                            total_installs = 0
                    except:
                        total_installs = 0
                    
                    st.markdown(f"""
                    <div class="metric-weather">
                        <h3>{total_installs:,.0f}</h3>
                        <p>æ€»å®‰è£…é‡</p>
                    </div>
                    """, unsafe_allow_html=True)
            
            # æ•°æ®å¯è§†åŒ–å›¾è¡¨
            st.markdown("### ğŸ“Š å¯è§†åŒ–åˆ†æ")
            viz_cols = st.columns(2, gap="large")
            
            with viz_cols[0]:
                st.markdown('<div class="data-preview">', unsafe_allow_html=True)
                fig_line = create_weather_visualization(integrated_dau, "ğŸ“ˆ DAUè¶‹åŠ¿åˆ†æ", "line")
                if fig_line == "streamlit_chart":
                    pass  # å›¾è¡¨å·²ç»é€šè¿‡streamlitæ˜¾ç¤º
                elif fig_line:
                    st.pyplot(fig_line, use_container_width=True)
                    plt.close(fig_line)  # é‡Šæ”¾å†…å­˜
                st.markdown('</div>', unsafe_allow_html=True)
            
            with viz_cols[1]:
                st.markdown('<div class="data-preview">', unsafe_allow_html=True)
                fig_bar = create_weather_visualization(integrated_dau, "ğŸ” æ¸ é“å¯¹æ¯”åˆ†æ", "bar")
                if fig_bar == "streamlit_chart":
                    pass  # å›¾è¡¨å·²ç»é€šè¿‡streamlitæ˜¾ç¤º
                elif fig_bar:
                    st.pyplot(fig_bar, use_container_width=True)
                    plt.close(fig_bar)  # é‡Šæ”¾å†…å­˜
                st.markdown('</div>', unsafe_allow_html=True)
            
            # æ•°æ®é¢„è§ˆè¡¨æ ¼
            st.markdown("### ğŸ“‹ æ•°æ®é¢„è§ˆ")
            st.markdown('<div class="weather-tabs">', unsafe_allow_html=True)
            preview_tabs = st.tabs(["ğŸ¯ ä¸‰ç«¯DAUæ±‡æ€»"] + [f"ğŸŒ¤ï¸ {ch.upper()}æ¸ é“" for ch in st.session_state.dau_results.keys()])
            st.markdown('</div>', unsafe_allow_html=True)
            
            with preview_tabs[0]:
                st.markdown('<div class="data-preview">', unsafe_allow_html=True)
                st.dataframe(
                    integrated_dau.head(15), 
                    use_container_width=True,
                    hide_index=True
                )
                st.markdown('</div>', unsafe_allow_html=True)
            
            for i, (channel, df) in enumerate(st.session_state.dau_results.items()):
                with preview_tabs[i + 1]:
                    st.markdown('<div class="data-preview">', unsafe_allow_html=True)
                    st.dataframe(
                        df.head(15), 
                        use_container_width=True,
                        hide_index=True
                    )
                    st.markdown('</div>', unsafe_allow_html=True)
            
            # ä¸‹è½½åŒºåŸŸ
            st.markdown("### ğŸ’¾ æ•°æ®å¯¼å‡º")
            download_cols = st.columns([2, 1, 1, 1, 1])
            
            today = datetime.datetime.now().strftime("%m.%d")
            
            with download_cols[0]:
                csv_data = integrated_dau.to_csv(index=False, encoding='utf-8-sig')
                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½ä¸‰ç«¯DAUæ±‡æ€»æ•°æ®",
                    data=csv_data.encode('utf-8-sig'),
                    file_name=f"{today}_ä¸‰ç«¯DAUæ±‡æ€».csv",
                    mime="text/csv",
                    type="primary"
                )
            
            # åˆ†æ¸ é“ä¸‹è½½
            for i, (channel, df) in enumerate(st.session_state.dau_results.items()):
                col_idx = (i + 1) % 4 + 1
                with download_cols[col_idx]:
                    csv_data = df.to_csv(index=False, encoding='utf-8-sig')
                    st.download_button(
                        label=f"{channel.upper()}",
                        data=csv_data.encode('utf-8-sig'),
                        file_name=f"{today}_DAU_{channel}.csv",
                        mime="text/csv",
                        key=f"dau_{channel}"
                    )
    
    # ç•™å­˜æ•°æ®å¯è§†åŒ–
    if 'retention_results' in st.session_state and st.session_state.retention_results:
        st.markdown("---")
        st.markdown("## ğŸ”„ ç•™å­˜æ•°æ®æ´å¯ŸæŠ¥å‘Š")
        
        # åˆ›å»ºæ•´åˆæ•°æ®
        integrated_retention = create_integrated_retention(st.session_state.retention_results)
        
        if not integrated_retention.empty:
            # ç•™å­˜æ•°æ®æŒ‡æ ‡
            retention_metric_cols = st.columns(3)
            with retention_metric_cols[0]:
                st.markdown(f"""
                <div class="metric-weather">
                    <h3>{len(st.session_state.retention_results)}</h3>
                    <p>ç•™å­˜æ¸ é“</p>
                </div>
                """, unsafe_allow_html=True)
            
            with retention_metric_cols[1]:
                total_users = 0
                if 'Users' in integrated_retention.columns:
                    try:
                        users_col = integrated_retention['Users'].replace('N/A', '0')
                        users_col = users_col.astype(str).str.replace(',', '')
                        total_users = pd.to_numeric(users_col, errors='coerce').sum()
                        if pd.isna(total_users):
                            total_users = 0
                    except:
                        total_users = 0
                
                st.markdown(f"""
                <div class="metric-weather">
                    <h3>{total_users:,.0f}</h3>
                    <p>æ€»ç”¨æˆ·æ•°</p>
                </div>
                """, unsafe_allow_html=True)
            
            with retention_metric_cols[2]:
                avg_retention = 0
                day1_cols = [col for col in integrated_retention.columns if 'day1' in col.lower()]
                if day1_cols:
                    try:
                        retention_values = pd.to_numeric(integrated_retention[day1_cols[0]], errors='coerce')
                        avg_retention = retention_values.mean() * 100
                        if pd.isna(avg_retention):
                            avg_retention = 0
                    except:
                        avg_retention = 0
                
                st.markdown(f"""
                <div class="metric-weather">
                    <h3>{avg_retention:.1f}%</h3>
                    <p>å¹³å‡æ¬¡æ—¥ç•™å­˜</p>
                </div>
                """, unsafe_allow_html=True)
            
            # ç•™å­˜å¯è§†åŒ–å›¾è¡¨
            st.markdown("### ğŸ“Š ç•™å­˜åˆ†æå›¾è¡¨")
            retention_viz_cols = st.columns(2, gap="large")
            
            with retention_viz_cols[0]:
                st.markdown('<div class="data-preview">', unsafe_allow_html=True)
                fig_retention = create_weather_visualization(integrated_retention, "ğŸ“ˆ ç•™å­˜ç‡è¶‹åŠ¿", "line")
                if fig_retention == "streamlit_chart":
                    pass  # å›¾è¡¨å·²ç»é€šè¿‡streamlitæ˜¾ç¤º
                elif fig_retention:
                    st.pyplot(fig_retention, use_container_width=True)
                    plt.close(fig_retention)  # é‡Šæ”¾å†…å­˜
                st.markdown('</div>', unsafe_allow_html=True)
            
            with retention_viz_cols[1]:
                st.markdown('<div class="data-preview">', unsafe_allow_html=True)
                fig_retention_bar = create_weather_visualization(integrated_retention, "ğŸ” æ¸ é“ç•™å­˜å¯¹æ¯”", "bar")
                if fig_retention_bar == "streamlit_chart":
                    pass  # å›¾è¡¨å·²ç»é€šè¿‡streamlitæ˜¾ç¤º
                elif fig_retention_bar:
                    st.pyplot(fig_retention_bar, use_container_width=True)
                    plt.close(fig_retention_bar)  # é‡Šæ”¾å†…å­˜
                st.markdown('</div>', unsafe_allow_html=True)
            
            # ç•™å­˜æ•°æ®é¢„è§ˆ
            st.markdown("### ğŸ“‹ ç•™å­˜æ•°æ®é¢„è§ˆ")
            st.markdown('<div class="weather-tabs">', unsafe_allow_html=True)
            retention_preview_tabs = st.tabs(["ğŸ¯ ä¸‰ç«¯ç•™å­˜æ±‡æ€»"] + [f"ğŸŒ§ï¸ {ch.upper()}æ¸ é“" for ch in st.session_state.retention_results.keys()])
            st.markdown('</div>', unsafe_allow_html=True)
            
            with retention_preview_tabs[0]:
                st.markdown('<div class="data-preview">', unsafe_allow_html=True)
                st.dataframe(
                    integrated_retention.head(15), 
                    use_container_width=True,
                    hide_index=True
                )
                st.markdown('</div>', unsafe_allow_html=True)
            
            for i, (channel, df) in enumerate(st.session_state.retention_results.items()):
                with retention_preview_tabs[i + 1]:
                    st.markdown('<div class="data-preview">', unsafe_allow_html=True)
                    st.dataframe(
                        df.head(15), 
                        use_container_width=True,
                        hide_index=True
                    )
                    st.markdown('</div>', unsafe_allow_html=True)
            
            # ç•™å­˜æ•°æ®ä¸‹è½½
            st.markdown("### ğŸ’¾ ç•™å­˜æ•°æ®å¯¼å‡º")
            retention_download_cols = st.columns([2, 1, 1, 1, 1])
            
            with retention_download_cols[0]:
                csv_data = integrated_retention.to_csv(index=False, encoding='utf-8-sig')
                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½ä¸‰ç«¯ç•™å­˜æ±‡æ€»æ•°æ®",
                    data=csv_data.encode('utf-8-sig'),
                    file_name=f"{today}_ä¸‰ç«¯ç•™å­˜æ±‡æ€».csv",
                    mime="text/csv",
                    type="primary",
                    key="retention_integrated"
                )
            
            # åˆ†æ¸ é“ä¸‹è½½
            for i, (channel, df) in enumerate(st.session_state.retention_results.items()):
                col_idx = (i + 1) % 4 + 1
                with retention_download_cols[col_idx]:
                    csv_data = df.to_csv(index=False, encoding='utf-8-sig')
                    st.download_button(
                        label=f"{channel.upper()}",
                        data=csv_data.encode('utf-8-sig'),
                        file_name=f"{today}_ç•™å­˜_{channel}.csv",
                        mime="text/csv",
                        key=f"retention_{channel}"
                    )
    
    # ä½¿ç”¨æŒ‡å—ï¼ˆåœ¨æ²¡æœ‰æ•°æ®æ—¶æ˜¾ç¤ºï¼‰
    if not ('dau_results' in st.session_state and st.session_state.dau_results) and not ('retention_results' in st.session_state and st.session_state.retention_results):
        st.markdown("---")
        st.markdown("## ğŸŒˆ å¼€å§‹æ‚¨çš„æ•°æ®åˆ†æä¹‹æ—…")
        
        guide_cols = st.columns(3)
        
        with guide_cols[0]:
            st.markdown("""
            <div class="weather-card">
                <div class="weather-icon">ğŸ“</div>
                <h4>1. ä¸Šä¼ æ•°æ®æ–‡ä»¶</h4>
                <p style="color: #666;">
                å°†æ‚¨çš„DAUå’Œç•™å­˜æ•°æ®æ–‡ä»¶æ‹–æ‹½åˆ°å¯¹åº”çš„ä¸Šä¼ åŒºåŸŸ
                </p>
            </div>
            """, unsafe_allow_html=True)
        
        with guide_cols[1]:
            st.markdown("""
            <div class="weather-card">
                <div class="weather-icon">âš¡</div>
                <h4>2. æ™ºèƒ½æ•°æ®å¤„ç†</h4>
                <p style="color: #666;">
                ç³»ç»Ÿè‡ªåŠ¨è¯†åˆ«æ ¼å¼ï¼Œæ¸…æ´—æ•°æ®ï¼Œç”Ÿæˆæ ‡å‡†åŒ–æŠ¥å‘Š
                </p>
            </div>
            """, unsafe_allow_html=True)
        
        with guide_cols[2]:
            st.markdown("""
            <div class="weather-card">
                <div class="weather-icon">ğŸ“Š</div>
                <h4>3. æ´å¯Ÿä¸å¯¼å‡º</h4>
                <p style="color: #666;">
                æŸ¥çœ‹å¯è§†åŒ–åˆ†æç»“æœï¼Œå¯¼å‡ºå¤„ç†åçš„æ•°æ®æ–‡ä»¶
                </p>
            </div>
            """, unsafe_allow_html=True)
    
    # åŠŸèƒ½è¯´æ˜ï¼ˆæŠ˜å æ˜¾ç¤ºï¼‰
    with st.expander("ğŸ“š å¹³å°åŠŸèƒ½è¯¦è§£", expanded=False):
        st.markdown("""
        ### ğŸ¯ æ ¸å¿ƒèƒ½åŠ›
        
        **ğŸ“Š DAUæ•°æ®æ™ºèƒ½åˆ†æ**
        - æ”¯æŒå¤šæ¸ é“æ–‡ä»¶è‡ªåŠ¨è¯†åˆ«ï¼šMVPã€Androidã€iOS
        - æ™ºèƒ½æ•°æ®æ¸…æ´—å’Œæ ‡å‡†åŒ–å¤„ç†
        - å®æ—¶è¶‹åŠ¿åˆ†æå’Œå¯è§†åŒ–å›¾è¡¨ç”Ÿæˆ
        - å¼‚å¸¸æ•°æ®æ£€æµ‹å’Œä¿®å¤
        
        **ğŸ”„ ç•™å­˜æ•°æ®æ·±åº¦åˆ†æ**
        - è‡ªåŠ¨è®¡ç®—1-7æ—¥ã€14æ—¥ã€30æ—¥ç•™å­˜ç‡
        - å¤šæ¸ é“ç•™å­˜è¡¨ç°å¯¹æ¯”åˆ†æ
        - ç”¨æˆ·è¡Œä¸ºæ¨¡å¼è¯†åˆ«å’Œé¢„æµ‹
        - ç•™å­˜æ¼æ–—åˆ†æå’Œä¼˜åŒ–å»ºè®®
        
        **ğŸ“ˆ å¯è§†åŒ–åˆ†æå¼•æ“**
        - äº¤äº’å¼å›¾è¡¨ç”Ÿæˆï¼šè¶‹åŠ¿çº¿ã€æŸ±çŠ¶å›¾ã€çƒ­åŠ›å›¾
        - å¤šç»´åº¦æ•°æ®é€è§†å’Œé’»å–åˆ†æ
        - å®æ—¶æ•°æ®æ›´æ–°å’ŒåŠ¨æ€å±•ç¤º
        - è‡ªå®šä¹‰æ—¶é—´èŒƒå›´å’ŒæŒ‡æ ‡ç­›é€‰
        
        ### ğŸ“ æ”¯æŒçš„æ–‡ä»¶æ ¼å¼
        
        **DAUæ•°æ®æ–‡ä»¶**
        - å‘½åæ ¼å¼ï¼š`dau_æ¸ é“_æ—¥æœŸ.csv`
        - ç¤ºä¾‹ï¼š`dau_mvp_3.17.csv`, `dau_and_3.18.csv`, `dau_ios_3.19.csv`
        - æ”¯æŒUTF-8å’ŒGBKç¼–ç æ ¼å¼
        
        **ç•™å­˜æ•°æ®æ–‡ä»¶**
        - å‘½åæ ¼å¼ï¼š`retention_æ¸ é“.csv`
        - ç¤ºä¾‹ï¼š`retention_mvp.csv`, `retention_and.csv`, `retention_ios.csv`
        - è‡ªåŠ¨è¯†åˆ«æ­£å¼ç‰ˆå’Œæµ‹è¯•ç‰ˆæ•°æ®
        
        ### ğŸš€ æ™ºèƒ½ç‰¹æ€§
        
        - **è‡ªåŠ¨ç¼–ç è¯†åˆ«**ï¼šæ™ºèƒ½æ£€æµ‹æ–‡ä»¶ç¼–ç ï¼Œç¡®ä¿ä¸­æ–‡å†…å®¹æ­£ç¡®æ˜¾ç¤º
        - **æ•°æ®ç±»å‹æ¨æ–­**ï¼šè‡ªåŠ¨è¯†åˆ«æ•°å€¼ã€æ—¥æœŸã€æ–‡æœ¬ç­‰æ•°æ®ç±»å‹
        - **å¼‚å¸¸å¤„ç†**ï¼šæ™ºèƒ½å¤„ç†ç¼ºå¤±å€¼ã€å¼‚å¸¸å€¼å’Œæ ¼å¼é”™è¯¯
        - **å†…å­˜ä¼˜åŒ–**ï¼šé«˜æ•ˆçš„æ•°æ®å¤„ç†ç®—æ³•ï¼Œæ”¯æŒå¤§æ–‡ä»¶åˆ†æ
        - **å®æ—¶åé¦ˆ**ï¼šå¤„ç†è¿›åº¦å®æ—¶æ˜¾ç¤ºï¼Œå¼‚å¸¸æƒ…å†µåŠæ—¶æé†’
        
        ### ğŸ’¡ ä½¿ç”¨å»ºè®®
        
        1. **æ–‡ä»¶å‡†å¤‡**ï¼šç¡®ä¿æ–‡ä»¶å‘½åç¬¦åˆè§„èŒƒï¼Œæ•°æ®æ ¼å¼æ ‡å‡†
        2. **æ‰¹é‡ä¸Šä¼ **ï¼šæ”¯æŒåŒæ—¶ä¸Šä¼ å¤šä¸ªæ–‡ä»¶ï¼Œç³»ç»Ÿè‡ªåŠ¨è¯†åˆ«å’Œåˆ†ç±»
        3. **ç»“æœéªŒè¯**ï¼šæŸ¥çœ‹ç”Ÿæˆçš„å¯è§†åŒ–å›¾è¡¨ï¼ŒéªŒè¯æ•°æ®å¤„ç†ç»“æœ
        4. **å®šæœŸåˆ†æ**ï¼šå»ºè®®å®šæœŸä½¿ç”¨æœ¬å¹³å°è¿›è¡Œæ•°æ®åˆ†æå’Œç›‘æ§
        """)
    
    # é¡µè„š
    st.markdown("---")
    st.markdown("""
    <div style='text-align: center; color: white; padding: 3rem; background: rgba(255, 255, 255, 0.1); border-radius: 20px; backdrop-filter: blur(10px); margin: 2rem 0;'>
        <h3 style='margin: 0; font-family: Inter; font-weight: 600;'>ğŸŒ¤ï¸ Weather Data Analytics</h3>
        <p style='margin: 0.5rem 0 0 0; opacity: 0.9; font-family: Inter;'>å¢¨è¿¹å¤©æ°”æ•°æ®åˆ†æå¹³å° | è®©æ•°æ®æ´å¯Ÿå¦‚å¤©æ°”é¢„æŠ¥èˆ¬ç²¾å‡†</p>
        <small style='opacity: 0.7;'>æ™ºèƒ½åˆ†æ â€¢ æ·±åº¦æ´å¯Ÿ â€¢ ç²¾å‡†é¢„æµ‹</small>
    </div>
    """, unsafe_allow_html=True)

# åˆå§‹åŒ–session state
if 'dau_results' not in st.session_state:
    st.session_state.dau_results = None
if 'retention_results' not in st.session_state:
    st.session_state.retention_results = None

if __name__ == "__main__":
    main()
